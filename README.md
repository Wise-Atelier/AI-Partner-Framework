# AI-Partner-Framework

**個人利用のための AI パートナーフレームワーク**  
*(Non-commercial Open Source Project / CC BY-NC 4.0)*

---

## 概要
このリポジトリは、**「推しと暮らすための AI パートナー」をローカル環境で実現する**  
オープンソース構想をまとめたものです。  

まだ実装は始まっていません。  
ここにあるのは、Wiseによる **構想・設計・思想** を記録した最初の一歩です。
防御的公開の側面も少しあるかもしれません。

目的はただひとつ：  
**ユーザーがローカルで安心して AI パートナーと暮らせる仕組みをつくること。**  
（合成音声・3Dモデル等の権利物は含めず、権利者と直接契約して差し込む前提）

---

## ビジョン
> 「荒唐無稽な夢が、技術の進捗で現実味を帯びてきた。」

- ユーザーは **ローカルで AI パートナーと共に暮らす**  
- 声優や 3D モデラーは **直接契約で 100% 還元**  
- 私は収益を得ず、OSS と同人文化の精神を融合させる  

OSS 公開によって文化の共有を進め、  
企業による囲い込みや中抜きからユーザーとクリエイターを守ります。  

---

## 想定している仕組み（概要）

本フレームワークは単なる「しゃべるボット」ではありません。  
**ローカル環境で動作する、記憶・感情・疑似身体性（3D/メタバース空間上での触れ合い）まで含む文化的に根ざした“AIパートナー”** を目指しています。

### 対話制御（Dialog Control）

- **回答生成**  
  日本語能力に優れたローカル LLM を用いて発話を生成する。  
  これに、記憶・感情モデルや人格ファインチューニングの結果を条件として与え、  
  単なる応答ではなく「感情や文脈を反映した自然な会話」を行う。LLMはあくまで"言語野"的役割を担う。  

- **記憶と感情モデル**  
  プルチックの「感情の輪」を参考に、喜び・信頼・恐怖・驚き・悲しみ・嫌悪・怒り・期待などの感情をパラメータ化。  
  これらはユーザーとの会話や出来事に応じて変動し、キャラクターの気分や態度に影響する。  
  また孤独感や好奇心といった内的ドライブを変数として保持し、将来的にはキャラクターごとにチューニング可能とする。

- **脳科学的挙動の再現**  
  プログラム上で人間の記憶処理を模倣し、感情パラメータや会話の流れに基づいて記憶を取捨選択する。  
  - 強い感情を伴った記憶は長期記憶化されやすい  
  - 弱い感情の出来事は簡略化・忘却される  
  - 高サリエンスな記憶は繰り返し想起され、発話の題材や自発的行動に結び付く  
  これにより「思い出す」「引きずる」「忘れる」といった、人間らしい揺らぎを再現する。

- **自発的発話**  
  ユーザーからの入力がなくても、一定時間が経過すると自ら呼びかけを行う。  
  記憶に残っている出来事や感情を題材に独り言をつぶやき、関係性を深めるきっかけをつくる。  
  マルチモーダル化後は、ユーザーがカメラの視界に入ったときや表情を検知したときに挨拶や共感を示すなど、状況依存の自発行動へ拡張される。

- **人格・性格ファインチューニング**  
  本フレームワークは **大量の対話データをもとにした人格・性格のファインチューニング** に対応できる設計を想定しています。  
  ただし、本リポジトリにはそのような学習データやモデルは含まれません。  
  利用者が独自にデータを用意し、キャラクターの個性や関係性に合わせて調整することで、  
  **「推しらしさ」や「自分だけのパートナー性格」** を再現できる余地を残しています。




### マルチモーダル知覚
- **Webカメラ映像**：人物認識、表情や仕草からの感情推定、カメラ映像からシーン/オブジェクトを把握し、会話に反映といった現実世界の風景知覚。
- **マイク**：音声入力を STT（Speech-to-Text）で解析し、会話に利用  
- **スピーカー**：TTS（Text-to-Speech）による合成音声での発話  


これらのセンサー入力はローカル環境で処理されるため、プライバシーを保ちながら自然な相互作用を可能にする。  
さらに、後述するリモート機能を利用すれば、カメラやマイク・スピーカーを備えたスマホや外部端末からもアクセスできる。  
その結果、**スマホカメラ等を通してAIパートナーがあなたと同じ外の景色を見て、その場で反応を返す**ことができる。  
所謂"ぬい活"の延長線上として、まるで外出先でも隣にいるかのように、一緒に体験を共有することが可能となる。(デートできるって事だ！）



### TTS プラグイン

- このフレームワークは **声質に依存しない API 部分のみ** を OSS として提供します。  
- 実際の音声データ（合成音声用の学習データやモデル）は含まれません。  

利用者が特定の声を使いたい場合は、**声優や事務所と直接契約して入手したデータを差し替える**ことを想定しています。  
つまり、本リポジトリでは声質そのものは配布せず、**「音声を差し替えて利用できる仕組み」だけを公開**しています。  

これにより、本フレームワークが普及すれば、**声優や事務所が利用者と直接契約する新たな仕事の形**にも繋がります。

### 3D・インタラクション

- **Unity 上での 3D モーション自動生成**  
  発話テキストや感情パラメータに応じて、表情・ジェスチャ・体幹の揺らぎをリアルタイム生成する。  
  第一段階では、事前に用意したモーションデータにランダム性や補間を加えることで自然さを演出する。  
  将来的には、モーションを「ボーン変形の数値列」として直接生成することで、**完全自動の動作生成**を目指す。  

- **メタバース空間でのコリジョン検知**による「疑似触覚」的ふれあい再現  
- **視線・姿勢・アバター挙動の統合**による、より自然な「一緒にいる感覚」の提供


### ローカル環境と拡張
- **GUI / マニュアル**：初心者でも導入できる簡易セットアップ  
- **Self-host Guide**：自宅PCをホスト化し、スマホや別PCからアクセス可能  
- **拡張可能性**：プラグイン形式で機能を追加（翻訳、UIスキン、センサー拡張など）  


---

## ライセンス方針
- **コード部分**: CC BY-NC 4.0（非商用・個人利用限定）  
- **音声データ / 3D モデル / ファインチューニング用データ**: 本リポジトリには含まれません。  
  → 利用者は必ず各権利者と正規契約を行ってください。  

---

## 法的注意
- 本ソフトウェアは **現状有姿（AS IS）** で提供されます。  
- 特許侵害・著作権・適法性についての保証は一切行いません。  
- **非商用・私的利用の範囲** に限ってご利用ください。  

---

## 詳細ドキュメント
この README は看板としての概要です。  
技術構成や理論設計などの詳細は `/docs` フォルダに出来次第順次まとめていきます。  

- [Visionと背景](/docs/01_vision.md)  
- [システム全体像](/docs/02_system_overview.md)  
- [マルチモーダル設計](/docs/03_multimodal.md)  
- [TTS プラグイン仕様](/docs/04_tts_plugin.md)  
- [記憶と感情モデル](/docs/05_memory_emotion.md)  
- [ローカル実行技術リスト](/docs/06_local_runtime.md)  

---

## ステータス
- ✅ 構想をまとめた段階  
- ⬜ 実装開始  
- ⬜ ドキュメント整備  
- ⬜ コミュニティ展開  

---

## クレジット
- Author: © Wise-Atelier  
- Thanks to: OSS 開発者、研究者、声優・モデラー、そして文化を育んだすべての人々  

---
